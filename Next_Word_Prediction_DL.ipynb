{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next Word Prediction_DL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIiOyUFifOan"
      },
      "source": [
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZf2_GmXfwGf"
      },
      "source": [
        "path = '/content/drive/MyDrive/DL and NLP/DL/corpus.txt'\n",
        "corpus=open(path).read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "aCa2BSQujYj3",
        "outputId": "70199e9d-5c13-4f88-f30a-5bccf9d4b9eb"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Next Word Prediction is also called Language Modeling. It is the task of predicting what word comes next. It is one of the fundamental tasks of NLP and has many applications. You might be using it daily when you write texts or emails without realizing it.'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEOgCjCKgBj3"
      },
      "source": [
        "import re\n",
        "corpus=corpus.lower()\n",
        "clean_corpus=re.sub('[^a-z0-9]+',' ', corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "EuEyBnXEgLnv",
        "outputId": "7537e635-6e2a-46e3-b534-cc066139ddd6"
      },
      "source": [
        "clean_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'next word prediction is also called language modeling it is the task of predicting what word comes next it is one of the fundamental tasks of nlp and has many applications you might be using it daily when you write texts or emails without realizing it '"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gshJCxn0g7VX",
        "outputId": "bc74413e-9e93-480b-c895-36d1d126019e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra6rc6rJhaaf",
        "outputId": "d3c30271-d92f-4b75-c8bc-4ccabfeed66d"
      },
      "source": [
        "tokens = word_tokenize(clean_corpus)\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['next',\n",
              " 'word',\n",
              " 'prediction',\n",
              " 'is',\n",
              " 'also',\n",
              " 'called',\n",
              " 'language',\n",
              " 'modeling',\n",
              " 'it',\n",
              " 'is',\n",
              " 'the',\n",
              " 'task',\n",
              " 'of',\n",
              " 'predicting',\n",
              " 'what',\n",
              " 'word',\n",
              " 'comes',\n",
              " 'next',\n",
              " 'it',\n",
              " 'is',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'fundamental',\n",
              " 'tasks',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'and',\n",
              " 'has',\n",
              " 'many',\n",
              " 'applications',\n",
              " 'you',\n",
              " 'might',\n",
              " 'be',\n",
              " 'using',\n",
              " 'it',\n",
              " 'daily',\n",
              " 'when',\n",
              " 'you',\n",
              " 'write',\n",
              " 'texts',\n",
              " 'or',\n",
              " 'emails',\n",
              " 'without',\n",
              " 'realizing',\n",
              " 'it']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOc1GcA6jv-G"
      },
      "source": [
        "train_len = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4-B7CtYj2gu"
      },
      "source": [
        "text_sequences = []\n",
        "for i in range(train_len,len(tokens)+1):\n",
        "  seq = tokens[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4c3Pa4Oj5Yv",
        "outputId": "9210421b-7e2f-4113-82d0-6e5dbf925326"
      },
      "source": [
        "text_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['next', 'word', 'prediction'],\n",
              " ['word', 'prediction', 'is'],\n",
              " ['prediction', 'is', 'also'],\n",
              " ['is', 'also', 'called'],\n",
              " ['also', 'called', 'language'],\n",
              " ['called', 'language', 'modeling'],\n",
              " ['language', 'modeling', 'it'],\n",
              " ['modeling', 'it', 'is'],\n",
              " ['it', 'is', 'the'],\n",
              " ['is', 'the', 'task'],\n",
              " ['the', 'task', 'of'],\n",
              " ['task', 'of', 'predicting'],\n",
              " ['of', 'predicting', 'what'],\n",
              " ['predicting', 'what', 'word'],\n",
              " ['what', 'word', 'comes'],\n",
              " ['word', 'comes', 'next'],\n",
              " ['comes', 'next', 'it'],\n",
              " ['next', 'it', 'is'],\n",
              " ['it', 'is', 'one'],\n",
              " ['is', 'one', 'of'],\n",
              " ['one', 'of', 'the'],\n",
              " ['of', 'the', 'fundamental'],\n",
              " ['the', 'fundamental', 'tasks'],\n",
              " ['fundamental', 'tasks', 'of'],\n",
              " ['tasks', 'of', 'nlp'],\n",
              " ['of', 'nlp', 'and'],\n",
              " ['nlp', 'and', 'has'],\n",
              " ['and', 'has', 'many'],\n",
              " ['has', 'many', 'applications'],\n",
              " ['many', 'applications', 'you'],\n",
              " ['applications', 'you', 'might'],\n",
              " ['you', 'might', 'be'],\n",
              " ['might', 'be', 'using'],\n",
              " ['be', 'using', 'it'],\n",
              " ['using', 'it', 'daily'],\n",
              " ['it', 'daily', 'when'],\n",
              " ['daily', 'when', 'you'],\n",
              " ['when', 'you', 'write'],\n",
              " ['you', 'write', 'texts'],\n",
              " ['write', 'texts', 'or'],\n",
              " ['texts', 'or', 'emails'],\n",
              " ['or', 'emails', 'without'],\n",
              " ['emails', 'without', 'realizing'],\n",
              " ['without', 'realizing', 'it']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK3xlK5Vj8j3",
        "outputId": "8c152e5a-0bc5-44a4-bebd-2117d9b6440d"
      },
      "source": [
        "#converting the texts into integer sequence\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
        "sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[7, 6, 8],\n",
              " [6, 8, 2],\n",
              " [8, 2, 9],\n",
              " [2, 9, 10],\n",
              " [9, 10, 11],\n",
              " [10, 11, 12],\n",
              " [11, 12, 1],\n",
              " [12, 1, 2],\n",
              " [1, 2, 4],\n",
              " [2, 4, 13],\n",
              " [4, 13, 3],\n",
              " [13, 3, 14],\n",
              " [3, 14, 15],\n",
              " [14, 15, 6],\n",
              " [15, 6, 16],\n",
              " [6, 16, 7],\n",
              " [16, 7, 1],\n",
              " [7, 1, 2],\n",
              " [1, 2, 17],\n",
              " [2, 17, 3],\n",
              " [17, 3, 4],\n",
              " [3, 4, 18],\n",
              " [4, 18, 19],\n",
              " [18, 19, 3],\n",
              " [19, 3, 20],\n",
              " [3, 20, 21],\n",
              " [20, 21, 22],\n",
              " [21, 22, 23],\n",
              " [22, 23, 24],\n",
              " [23, 24, 5],\n",
              " [24, 5, 25],\n",
              " [5, 25, 26],\n",
              " [25, 26, 27],\n",
              " [26, 27, 1],\n",
              " [27, 1, 28],\n",
              " [1, 28, 29],\n",
              " [28, 29, 5],\n",
              " [29, 5, 30],\n",
              " [5, 30, 31],\n",
              " [30, 31, 32],\n",
              " [31, 32, 33],\n",
              " [32, 33, 34],\n",
              " [33, 34, 35],\n",
              " [34, 35, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOSjGRTtkCBO"
      },
      "source": [
        "sequences=np.asarray(sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-zzrxNskFf2",
        "outputId": "9becbf2b-eccc-4c9d-e2e4-1468dfb92bc4"
      },
      "source": [
        "#vocabulary size\n",
        "vocabulary_size = len(tokenizer.word_counts)+1\n",
        "vocabulary_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAUDTZmxkI-O"
      },
      "source": [
        "#trainX\n",
        "train_inputs=sequences[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAjoFQR_kLul",
        "outputId": "3afb823f-afa3-441a-e7b9-8eb5798b816e"
      },
      "source": [
        "train_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  6],\n",
              "       [ 6,  8],\n",
              "       [ 8,  2],\n",
              "       [ 2,  9],\n",
              "       [ 9, 10],\n",
              "       [10, 11],\n",
              "       [11, 12],\n",
              "       [12,  1],\n",
              "       [ 1,  2],\n",
              "       [ 2,  4],\n",
              "       [ 4, 13],\n",
              "       [13,  3],\n",
              "       [ 3, 14],\n",
              "       [14, 15],\n",
              "       [15,  6],\n",
              "       [ 6, 16],\n",
              "       [16,  7],\n",
              "       [ 7,  1],\n",
              "       [ 1,  2],\n",
              "       [ 2, 17],\n",
              "       [17,  3],\n",
              "       [ 3,  4],\n",
              "       [ 4, 18],\n",
              "       [18, 19],\n",
              "       [19,  3],\n",
              "       [ 3, 20],\n",
              "       [20, 21],\n",
              "       [21, 22],\n",
              "       [22, 23],\n",
              "       [23, 24],\n",
              "       [24,  5],\n",
              "       [ 5, 25],\n",
              "       [25, 26],\n",
              "       [26, 27],\n",
              "       [27,  1],\n",
              "       [ 1, 28],\n",
              "       [28, 29],\n",
              "       [29,  5],\n",
              "       [ 5, 30],\n",
              "       [30, 31],\n",
              "       [31, 32],\n",
              "       [32, 33],\n",
              "       [33, 34],\n",
              "       [34, 35]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPzQ8o3ZkOhW",
        "outputId": "d20f0a64-7046-45c7-e97a-0b5ea0f88fcd"
      },
      "source": [
        "seq_length=train_inputs.shape[1]\n",
        "seq_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMdn5J9pkSB-"
      },
      "source": [
        "#trainY\n",
        "train_targets=sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hepe-XMkUs2",
        "outputId": "0e71690b-a834-4daa-faf9-e95ba768f8e9"
      },
      "source": [
        "train_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  2,  9, 10, 11, 12,  1,  2,  4, 13,  3, 14, 15,  6, 16,  7,  1,\n",
              "        2, 17,  3,  4, 18, 19,  3, 20, 21, 22, 23, 24,  5, 25, 26, 27,  1,\n",
              "       28, 29,  5, 30, 31, 32, 33, 34, 35,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSs4dLa4kXGm"
      },
      "source": [
        "train_targets = to_categorical(train_targets, num_classes=vocabulary_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0hrNerIka1H"
      },
      "source": [
        "#required libraries\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1bxs1uQknS2"
      },
      "source": [
        "#lstm model\n",
        "class lstm(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        #simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        \n",
        "        #lstm \n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=2, bidirectional=False)\n",
        "        \n",
        "        #fully connected layer\n",
        "        self.linear = nn.Linear(hidden_size*seq_length,vocab_size)\n",
        "    \n",
        "    def forward(self, input_word):\n",
        "        #input sequence to embeddings\n",
        "        embedded = self.embed(input_word)\n",
        "        \n",
        "        #passing the embedding to lstm model\n",
        "        output, hidden = self.lstm(embedded)\n",
        "        \n",
        "        #reshaping\n",
        "        output=output.view(output.size(0), -1)\n",
        "        \n",
        "        #fully connected layer\n",
        "        output = self.linear(output)\n",
        "        return output,hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgRZZEnGkxIu"
      },
      "source": [
        "model=lstm(vocab_size=vocabulary_size,embed_size=128, hidden_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeSRCback0Pe",
        "outputId": "3e2a03c7-9c1c-4886-81a4-a43f62c6dcdf"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm(\n",
              "  (embed): Embedding(36, 128)\n",
              "  (lstm): LSTM(128, 256, num_layers=2)\n",
              "  (linear): Linear(in_features=512, out_features=36, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyB4vgsrk29W"
      },
      "source": [
        "#Adam optimizer\n",
        "optimizer= Adam(model.parameters(), lr=0.07)\n",
        "\n",
        "#loss\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crimRAs4k-Pf"
      },
      "source": [
        "#training the model\n",
        "def train(epoch):\n",
        "    #set the model to train\n",
        "    model.train()\n",
        "    tr_loss=0    \n",
        "    \n",
        "    #clearing the Gradients \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #predict the output\n",
        "    y_pred, (state_h, state_c) = model(torch.from_numpy(train_inputs))\n",
        "    \n",
        "    #compute the loss\n",
        "    loss=criterion(y_pred,torch.from_numpy(train_targets))\n",
        "    losses.append(loss)\n",
        "    \n",
        "    #backpropagate\n",
        "    loss.backward()\n",
        "\n",
        "    #update the parameters\n",
        "    optimizer.step()\n",
        "    tr_loss = loss.item()\n",
        "\n",
        "    print(\"Epoch : \",epoch,\"loss : \",loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYr9ObUQlB7W",
        "outputId": "2c31050d-31e9-45f8-feb4-b1a3664bf1f8"
      },
      "source": [
        "#number of epoch\n",
        "no_epoch=50\n",
        "losses=[]\n",
        "for epoch in range(1,no_epoch+1):\n",
        "    train(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  1 loss :  tensor(0.0873, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  2 loss :  tensor(0.0727, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  3 loss :  tensor(0.0602, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  4 loss :  tensor(0.0481, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  5 loss :  tensor(0.0401, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  6 loss :  tensor(0.0315, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  7 loss :  tensor(0.0252, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  8 loss :  tensor(0.0192, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  9 loss :  tensor(0.0151, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  10 loss :  tensor(0.0120, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  11 loss :  tensor(0.0098, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  12 loss :  tensor(0.0079, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  13 loss :  tensor(0.0063, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  14 loss :  tensor(0.0051, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  15 loss :  tensor(0.0042, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  16 loss :  tensor(0.0034, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  17 loss :  tensor(0.0028, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  18 loss :  tensor(0.0023, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  19 loss :  tensor(0.0020, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  20 loss :  tensor(0.0017, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  21 loss :  tensor(0.0014, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  22 loss :  tensor(0.0012, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  23 loss :  tensor(0.0011, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  24 loss :  tensor(0.0009, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  25 loss :  tensor(0.0008, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  26 loss :  tensor(0.0007, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  27 loss :  tensor(0.0007, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  28 loss :  tensor(0.0006, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  29 loss :  tensor(0.0005, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  30 loss :  tensor(0.0005, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  31 loss :  tensor(0.0005, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  32 loss :  tensor(0.0004, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  33 loss :  tensor(0.0004, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  34 loss :  tensor(0.0004, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  35 loss :  tensor(0.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  36 loss :  tensor(0.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  37 loss :  tensor(0.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  38 loss :  tensor(0.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  39 loss :  tensor(0.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  40 loss :  tensor(0.0003, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  41 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  42 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  43 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  44 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  45 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  46 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  47 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  48 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  49 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
            "Epoch :  50 loss :  tensor(0.0002, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "e0o6nDRsmmF2",
        "outputId": "3ed691ed-0712-4f28-b9ba-dc6d12313e2c"
      },
      "source": [
        "#plotting the loss, loss is decreasing for each epoch\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses, label='Training loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChO0ZPa2mpWm"
      },
      "source": [
        "def predict_next_word(text):\n",
        "    #set the model to evaluation\n",
        "    model.eval()\n",
        "\n",
        "    #preprocess\n",
        "    text = text.lower().strip()\n",
        "    \n",
        "    #converting the text to word tokens\n",
        "    input_tokens = word_tokenize(text)\n",
        "    \n",
        "    #converting the tokens to integer sequence\n",
        "    sequences = tokenizer.texts_to_sequences([input_tokens])\n",
        "    \n",
        "    #converting to array\n",
        "    sequences=np.asarray(sequences)\n",
        "    with torch.no_grad():\n",
        "        #converting to tensor\n",
        "        sequences=torch.from_numpy(sequences)\n",
        "        #predicting the output\n",
        "        predict,(hidden,cell)=model(sequences)\n",
        "    \n",
        "    #applying the softmax layer\n",
        "    softmax = torch.exp(predict)\n",
        "    prob = list(softmax.numpy())\n",
        "    \n",
        "    #index of the predict word\n",
        "    predictions = np.argmax(prob)\n",
        "\n",
        "    #converting the sequence back to word\n",
        "    next_word=tokenizer.sequences_to_texts([[predictions]])\n",
        "    return next_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S966XHwKmuX1",
        "outputId": "38327bed-f9ea-41bf-a100-4c6b64e0a5a2"
      },
      "source": [
        "input_text=\"next word\"\n",
        "print(\"Possible next word will be:\")\n",
        "predict_next_word(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possible next word will be:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['prediction']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80be0u37m1u1",
        "outputId": "0dd5e01f-8b13-4314-f059-e08027a6a3dd"
      },
      "source": [
        "input_text=\"Language Modeling\"\n",
        "print(\"Possible next word will be:\")\n",
        "predict_next_word(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Possible next word will be:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}